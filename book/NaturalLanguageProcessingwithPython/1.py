#! /usr/bin/env python3

from nltk.book import *

#text1.concordance("monstrous") # Find keyword
#text1.similar("monstrous") # 同じ文脈
#text2.common_contexts(["monstrous", "very"]) # 共通に使われる文脈
#text4.dispersion_plot(["citizens", "democracy", "freedom", "duties", "America"])
#text3.generate(words=None)
#print(len(text3))
#print(sorted(set(text3)))
#print(len(text3)/len(set(text3)))
#print(text3.count("smote"))

#fdist1 = FreqDist(text1)
#print(fdist1)
#vocabulary1 = list(fdist1.keys())
#print(vocabulary1[:50])
#print(fdist1['whale'])
#fdist1.plot(50, cumulative=True)
#print(fdist1.hapaxes())

#V = set(text1)
#long_words = [w for w in V if len(w) > 15]
#print(sorted(long_words))
#fdist5 = FreqDist(text5)
#print(sorted([w for w in set(text5) if len(w) > 7 and fdist5[w] > 7]))

#print(bigrams(['more', 'is', 'said', 'than', 'done']))
#print(text4.collocations())

#print([len(w) for w in text1])
#fdist = FreqDist([len(w) for w in text1])
#print(fdist)
#print(fdist.keys())
#print(fdist.items())
#print(fdist.max())
#print(fdist[3])
#print(fdist.freq(3))

#print(sent7)
#print(babelize_shell()) # dont use

##import nltk
##nltk.chat.chatbots()
